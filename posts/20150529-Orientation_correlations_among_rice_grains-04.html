<!DOCTYPE html>
<html>
<head>
<title>Orientation correlations among rice grains, part 4: defining the ROI</title>
<!-- 2015-07-01 Wed 09:05 -->
<meta  charset="utf-8">
<meta  name="generator" content="Org-mode">
<meta  name="author" content="Sébastien Brisard">
<link rel="stylesheet" href="../theme.css"/><link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="preamble" class="status">
<img id="banner" src="../images/banner.jpg"/>
<div class="navbar">
<span class="sitename"><a href="../index.html" title="">Sébastien Brisard's blog</a></span>
<ul>
<li><a href="../index.html" title="Home"><span class="fa fa-home"></span></a></li>
<li><a href="../pages/about.html" title="About me"><span class="fa fa-user"></span></a></li>
<li><a href="../pages/references.html" title="References"><span class="fa fa-book"></span></a></li>
<li><a href="archives.html" title="Archives"><span class="fa fa-archive"></span></a></li>
<li><a href="https://github.com/sbrisard" title="GitHub"><span class="fa fa-github"></span></a></li>
<li><a href="https://bitbucket.org/sbrisard" title="Bitbucket"><span class="fa fa-bitbucket"></span></a></li>
<li><a href="https://twitter.com/SebBrisard" title="Twitter"><span class="fa fa-twitter"></span></a></li>
<li><a href="../feed.xml" title="RSS"><span class="fa fa-rss"></span></a></li>
</ul>
</div>
</div>
<div id="content">
<h1 class="title">Orientation correlations among rice grains, part 4: defining the ROI</h1>
<p>
In the <a href="./20150330-Orientation_correlations_among_rice_grains-03.html">previous instalment</a> of this series, we obtained binned slices of the sample. Fig. <a href="#fig:1">1</a> is a typical example of these binned slices. We now want to segment the rice grains. However, the analysis (in particular, Otsu thresholding) might be perturbed by the fact that the walls of the sample container are visible on the 3D image. In this post, I will show how we can locate these walls. Then, any subsequent analysis will be performed within the Region Of Interest (ROI) thus defined.
</p>


<div id="fig:1" class="figure">
<p><img src="./20150529-Orientation_correlations_among_rice_grains-04/rice-bin_4x4x4-099.png" alt="rice-bin_4x4x4-099.png" width="50%">
</p>
<p><span class="figure-number">Figure 1:</span> A typical slice of the 3D reconstruction of the sample. The original image has been reduced by 4×4×4 binning; the size of each binned slice is 436×437.</p>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">The circle Hough Transform</h2>
<div class="outline-text-2" id="text-1">
<p>
The sample container is cylindrical; since it was nearly vertical during the tomography experiment, its trace is a circular ring on each slice. We are going to use the <a href="http://en.wikipedia.org/wiki/Circle_Hough_Transform">Circle Hough Transform</a> in order to locate the inner and outer circular boundaries which define this ring. To do so, we will use <a href="https://www.python.org/">python</a>, <a href="http://www.numpy.org/">numpy</a> and <a href="http://scikit-image.org/docs/dev/api/skimage.html">scikit-image</a>. We first import these modules, and load the image
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-keyword">import</span> os.path

<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> skimage.color <span class="org-keyword">import</span> gray2rgb
<span class="org-keyword">from</span> skimage.draw <span class="org-keyword">import</span> circle_perimeter
<span class="org-keyword">from</span> skimage.feature <span class="org-keyword">import</span> canny
<span class="org-keyword">from</span> skimage.io <span class="org-keyword">import</span> imread, imsave
<span class="org-keyword">from</span> skimage.transform <span class="org-keyword">import</span> hough_circle
<span class="org-keyword">from</span> skimage.util <span class="org-keyword">import</span> img_as_ubyte

<span class="org-variable-name">root</span> = os.path.join(<span class="org-string">'.'</span>,
                    <span class="org-string">'20150529-Orientation_correlations_among_rice_grains-04'</span>)
<span class="org-variable-name">name</span> = os.path.join(root, <span class="org-string">'rice-bin_4x4x4-099.tif'</span>)
<span class="org-variable-name">img</span> = imread(name)

<span class="org-string">'Read {}x{} image.'</span>.<span class="org-builtin">format</span>(*img.shape)
</pre>
</div>

<pre class="example">
Read 437x436 image.
</pre>

<p>
Then, we locate the edges, by means of a standard <a href="http://en.wikipedia.org/wiki/Canny_edge_detector">Canny edge detector</a> (see also the <a href="http://scikit-image.org/docs/dev/api/skimage.feature.html#canny">API docs</a> of scikit-image).
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-variable-name">edges</span> = canny(img, sigma=0.)
imsave(os.path.join(root, <span class="org-string">'rice-bin_4x4x4-edges-099.png'</span>),
       img_as_ubyte(edges))
</pre>
</div>

<p>
The resulting image is shown in Fig. <a href="#fig:2">2</a>. It should be noted that due to the preliminary binning (which is nothing but a mean filter), the input image exhibits very little noise. Therefore, <code>sigma=0.0</code> in the above call to <code>skimage.feature.canny</code>.
</p>


<div id="fig:2" class="figure">
<p><img src="./20150529-Orientation_correlations_among_rice_grains-04/rice-bin_4x4x4-edges-099.png" alt="rice-bin_4x4x4-edges-099.png" width="50%">
</p>
<p><span class="figure-number">Figure 2:</span> Canny edge detection performed on the initial image shown in Fig. <a href="#fig:1">1</a>.</p>
</div>

<p>
We are now ready to compute the Circle Hough Transform. This transform aims at finding circles within an image. It was proposed by Duda and Hart (<a href="../pages/references.html#DUDA1971">1971</a>) (see also <a href="http://en.wikipedia.org/wiki/Hough_transform">Wikipedia</a>). It should be understood as a histogram in parameter space. More precisely, a point \((x, y)\) belongs to the circle centered at \((c_x, c_y)\) and of radius \(r\) if, and only if
</p>

\begin{equation*}
(x-c_x)^2+(y-c_y)^2=r^2.
\end{equation*}

<p>
The circle under consideration is parameterized by \((c_x, c_y, r)\). Conversely, given a point \((x, y)\), the set of circles to which this point belongs is given by the triplet \((c_x, c_y, r)\) such that
</p>

\begin{equation*}
(c_x-x)^2+(c_y-y)^2-r^2=0.
\end{equation*}

<p>
In the parameter space \((c_x, c_y, r)\), the set of circles to which point \((x, y)\) belongs is a <i>conical surface</i>. Its apex is \((x, y, 0)\), its axis is the \((0, 0, 1)\) direction and its aperture is 90°. As we are only interested in real circles, only the \(r\geq0\) half-space should be considered.
</p>

<p>
How is this representation in parameter space to be used? We consider a binary (0/1) image; let \(\{(x_i, y_i),i=1,\ldots,N\}\) denote the set of non-null pixels. We define \(\mathcal H_i\) as the 3D, binary image of the cone associated in the sphere parameter space with pixel \((x_i, y_i)\). The Hough transform is then the (possibly normalized) sum of all \(\mathcal H_i\)
</p>

\begin{equation*}
\mathcal H(c_x, c_y, r)=\sum_i\mathcal H_i(c_x, c_y, r).
\end{equation*}

<p>
\(\mathcal H\) should really be understood as a <i>histogram</i>. Indeed, a peak in \(\mathcal H\) indicates that the cones corresponding to many pixels intersect at the same point in parameter space. In other words, many pixels in the original image belong to the <i>same</i> circle. Finding circles in the original image therefore reduces to finding peaks in its Hough transform. That is what we are going to do presently. We must first compute the Hough transform. In order to reduce the CPU cost, we will only consider these circles whose radius is close to that of the sample container. We saw in <a href="./20150310-Orientation_correlations_among_rice_grains-02.html">part 2</a> of this series that the radius of the sample container is 25 mm, while the voxel size is approximately 0.03 mm; after binning, the voxel size is therefore 0.12 mm, and the radius of the sample container is approx. 25 / 0.12 = 208 px. In the following code, we ask for the circle Hough transform for circles with radii between 190 and 220 px.
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-variable-name">radii</span> = np.arange(190, 220)
<span class="org-variable-name">h</span> = hough_circle(edges, radii)
<span class="org-keyword">for</span> i, radius <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(radii):
    imsave(os.path.join(root,
                        <span class="org-string">'rice-bin_4x4x4-hough-099-{}.tif'</span>.<span class="org-builtin">format</span>(radius)),
           h[i, ...])
</pre>
</div>

<p>
The above code snippet saves a series of images, which is displayed below in 3D as an animated GIF (see Fig. <a href="#fig:3">3</a>). The two bright spots indicate the location of the inner and outer boundaries in the parameter space. We will use a very crude procedure to locate these two peaks (a more elaborate method is not required as we do not seek sub-pixel accuracy).
</p>


<div id="fig:3" class="figure">
<p><img src="./20150529-Orientation_correlations_among_rice_grains-04/rice-bin_4x4x4-hough-3D_rot-099.gif" alt="rice-bin_4x4x4-hough-3D_rot-099.gif" width="50%">
</p>
<p><span class="figure-number">Figure 3:</span> 3D view of the Hough transform. The two bright spots correspond to the inner and outer boundaries of the sample container.</p>
</div>

<p>
The code snippet below finds the two highest values of the Hough transform. The correct peak (inner boundary) corresponds to the <i>smallest</i> radius. Then, the coordinates of the center of the corresponding circle are found.
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-variable-name">h_max</span> = np.<span class="org-builtin">max</span>(h, axis=(1, 2))
<span class="org-variable-name">k</span> = np.<span class="org-builtin">min</span>(np.argsort(h_max)[-2:])
<span class="org-variable-name">radius</span> = radii[k]
<span class="org-variable-name">h</span> = h[k, ...]
<span class="org-variable-name">row</span>, <span class="org-variable-name">col</span> = np.unravel_index(np.argmax(h), h.shape)
<span class="org-string">'The inner boundary is centered at ({} px, {} px); its radius is {} px.'</span>.<span class="org-builtin">format</span>(<span class="org-whitespace-line">row, col, radius)</span>
</pre>
</div>

<pre class="example">
The inner boundary is centered at (219 px, 217 px); its radius is 208 px.
</pre>

<p>
The radius of the inner boundary turns out to be <i>exactly</i> 208 pixels! For visual inspection, this circle is overlaid on top of the original image (adapted from this <a href="http://scikit-image.org/docs/dev/auto_examples/plot_circular_elliptical_hough_transform.html#example-plot-circular-elliptical-hough-transform-py">scikit-image example</a>).
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-variable-name">img_rgb</span> = gray2rgb(img_as_ubyte(img))
<span class="org-variable-name">rows</span>, <span class="org-variable-name">cols</span> = circle_perimeter(row, col, radius, method=<span class="org-string">'andres'</span>)
<span class="org-variable-name">img_rgb</span>[rows, cols] = (255, 0, 0)
imsave(os.path.join(root, <span class="org-string">'rice-bin_4x4x4-boundary-099.png'</span>), img_rgb)
</pre>
</div>

<p>
Which produces the following image (see Fig. <a href="#fig:4">4</a>).
</p>


<div id="fig:4" class="figure">
<p><img src="./20150529-Orientation_correlations_among_rice_grains-04/rice-bin_4x4x4-boundary-099.png" alt="rice-bin_4x4x4-boundary-099.png" width="50%">
</p>
<p><span class="figure-number">Figure 4:</span> The original image overlaid with the identified boundary.</p>
</div>

<p>
A closer look (see Fig. <a href="#fig:5">5</a>) shows that we roughly achieved pixel accuracy, which will be sufficient for the analysis to come.
</p>


<div id="fig:5" class="figure">
<p><img src="./20150529-Orientation_correlations_among_rice_grains-04/rice-bin_4x4x4-roi_64x64+10+110-boundary-resized-099.png" alt="rice-bin_4x4x4-roi_64x64+10+110-boundary-resized-099.png" width="50%">
</p>
<p><span class="figure-number">Figure 5:</span> Close-up of Fig. <a href="#fig:4">4</a>; pixel accuracy was approximately achieved.</p>
</div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Analysis of the whole stack</h2>
<div class="outline-text-2" id="text-2">
<p>
We are now ready to carry out the above analysis on all 172 images of the stack. This is what the script below does (<a href="./20150529-Orientation_correlations_among_rice_grains-04/find_boundary.py">download</a>); in order to check that nothing went wrong, each image with overlaid boundary is saved for visual inspection.
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-keyword">import</span> os.path
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> skimage.color <span class="org-keyword">import</span> gray2rgb
<span class="org-keyword">from</span> skimage.draw <span class="org-keyword">import</span> circle_perimeter
<span class="org-keyword">from</span> skimage.feature <span class="org-keyword">import</span> canny
<span class="org-keyword">from</span> skimage.io <span class="org-keyword">import</span> imread, imsave
<span class="org-keyword">from</span> skimage.transform <span class="org-keyword">import</span> hough_circle
<span class="org-keyword">from</span> skimage.util <span class="org-keyword">import</span> img_as_ubyte


<span class="org-keyword">def</span> <span class="org-function-name">find_boundary</span>(img, min_radius, max_radius):
    <span class="org-variable-name">edges</span> = canny(img, sigma=0.)
    <span class="org-variable-name">radii</span> = np.arange(min_radius, max_radius)
    <span class="org-variable-name">h</span> = hough_circle(edges, radii)
    <span class="org-variable-name">h_max</span> = np.<span class="org-builtin">max</span>(h, axis=(1, 2))
    <span class="org-variable-name">k</span> = np.<span class="org-builtin">min</span>(np.argsort(h_max)[-2:])
    <span class="org-variable-name">radius</span> = radii[k]
    <span class="org-variable-name">h</span> = h[k, ...]
    <span class="org-variable-name">row</span>, <span class="org-variable-name">col</span> = np.unravel_index(np.argmax(h), h.shape)
    <span class="org-keyword">return</span> row, col, radius


<span class="org-keyword">def</span> <span class="org-function-name">draw_boundary</span>(img, row, col, radius):
    <span class="org-variable-name">img_rgb</span> = gray2rgb(img_as_ubyte(img))
    <span class="org-variable-name">rows</span>, <span class="org-variable-name">cols</span> = circle_perimeter(row, col, radius, method=<span class="org-string">'andres'</span>)
    <span class="org-variable-name">img_rgb</span>[rows, cols] = (255, 0, 0)
    <span class="org-keyword">return</span> img_rgb


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">'__main__'</span>:
    <span class="org-variable-name">root</span> = os.path.join(<span class="org-string">'F:'</span>, <span class="org-string">'sebastien'</span>, <span class="org-string">'experimental_data'</span>, <span class="org-string">'navier'</span>, <span class="org-string">'riz'</span>)
    <span class="org-variable-name">input_dir</span> = os.path.join(root, <span class="org-string">'bin_4x4x4'</span>)
    <span class="org-variable-name">output_dir</span> = os.path.join(root, <span class="org-string">'boundary'</span>)
    <span class="org-variable-name">input_name</span> = <span class="org-string">'rice-bin_4x4x4-{0:03d}.tif'</span>
    <span class="org-variable-name">output_name</span> = <span class="org-string">'rice-bin_4x4x4-boundary-{0:03d}.png'</span>
    <span class="org-variable-name">num_slices</span> = 172
    <span class="org-variable-name">min_radius</span> = 190
    <span class="org-variable-name">max_radius</span> = 220

    <span class="org-variable-name">circle_params</span> = np.zeros((num_slices, 3), dtype=np.uint16)
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_slices):
        <span class="org-variable-name">img</span> = imread(os.path.join(input_dir, input_name.<span class="org-builtin">format</span>(i)))
        <span class="org-variable-name">circle_params</span>[i] = find_boundary(img, min_radius, max_radius)
        <span class="org-variable-name">img</span> = draw_boundary(img, *circle_params[i])
        imsave(os.path.join(output_dir, output_name.<span class="org-builtin">format</span>(i)), img)
    np.save(<span class="org-string">'./circle_params.npy'</span>, circle_params)
</pre>
</div>

<p>
This script saves the parameters of each circular boundary in an array, which can be restored for further analysis.
</p>

<div class="org-src-container">

<pre class="src src-python"><span class="org-variable-name">a</span> = np.load(os.path.join(root, <span class="org-string">'circle_params.npy'</span>))
<span class="org-string">'avg = {}\nstd = {}'</span>.<span class="org-builtin">format</span>(a.mean(axis=0), a.std(axis=0))
</pre>
</div>

<pre class="example">
avg = [ 218.89534884  216.97674419  207.88372093]
std = [ 0.30610341  0.1507149   0.32055927]
</pre>

<p>
Which shows that there is very little variation of the circle parameters across the slices.
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Closing words</h2>
<div class="outline-text-2" id="text-3">
<p>
In this post, we saw how to define the (cylindrical) ROI on our stack of images. To do so, we used the Circle Hough Transform to find circular edges in the slices. In the next instalment of this series, I will start discussing segmentation <i>per se</i>.
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">Side-note: how to produce animated GIFs</h2>
<div class="outline-text-2" id="text-4">
<p>
The animated GIF in Fig. <a href="#fig:3">3</a> was produced with <a href="http://imagej.nih.gov/ij/">ImageJ</a>. The procedure is
</p>

<ol class="org-ol">
<li>Import the image sequence (File → Import → Image Sequence&#x2026;) called <code>rice-bin_4x4x4-hough-099-*.tif</code>,
</li>
<li>Image → Stacks → 3D Project&#x2026;
</li>
<li>Image → Lookup Tables → Fire
</li>
<li>File → Save As → Gif
</li>
</ol>

<p>
To change the frame rate, use Image → Stacks → Tools → Animation Options&#x2026;
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Except where otherwise noted, this blog</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://sbrisard.github.io/" property="cc:attributionName" rel="cc:attributionURL">Sébastien Brisard</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
This blog was generated with <a href="http://www.gnu.org/software/emacs/">Emacs</a> and <a href="http://orgmode.org/">Org mode</a>. The theme is inspired from <a href="http://orgmode.org/worg/">Worg</a>. Icons come from the <a href="http://fontawesome.io/">Font Awesome</a> icon set.</p><div id="disqus_thread"></div>
<script type="text/javascript">
var disqus_shortname = 'sbrisard';
var disqus_identifier = 'posts/20150529-Orientation_correlations_among_rice_grains-04';
var disqus_title = 'Orientation correlations among rice grains, part 4: defining the ROI';
var disqus_url = 'http://sbrisard.github.io/posts/20150529-Orientation_correlations_among_rice_grains-04.html';
(function() {
var dsq = document.createElement('script');
dsq.type = 'text/javascript';
dsq.async = true;
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
</body>
</html>
